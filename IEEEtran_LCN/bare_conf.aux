\relax 
\citation{Bernaille:2006:EAI:1368436.1368445}
\citation{DBLP:conf/iwcmc/GrimaudoMB12}
\citation{DBLP:conf/infocom/XieIKFN12}
\citation{ACAS}
\citation{conf/IEEEcit/YeXWP09}
\citation{DBLP:conf/noms/ParkWKH08}
\citation{ACAS}
\citation{DBLP:conf/infocom/XieIKFN12}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}}
\citation{ACAS}
\citation{ACAS}
\citation{Erman:2006:TCU:1162678.1162679}
\citation{Erman:2006:TCU:1162678.1162679}
\citation{Bernaille:2006:EAI:1368436.1368445}
\citation{Bernaille:2006:EAI:1368436.1368445}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Work and Motivation}{2}}
\newlabel{sec:related}{{II}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \% of training data v/s Accuracy with only average packet size as attribute. We have considered Average Packet Size as the only attribute for K-Means algorithm. We observe that accuracy reaches around 90\% when we have around 95\% of training data\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{early_app_identification}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Number of clusters v/s Accuracy for K-Means algorithm with All and Selected attributes\relax }}{3}}
\newlabel{fig_k_means_all}{{2}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Grouping of Attributes}{3}}
\newlabel{sec:grouping}{{III}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {III-A}}Preliminary Results}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Accuracy based on IAT group\relax }}{3}}
\newlabel{table_iat_group}{{II}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {III}{\ignorespaces Accuracy based on RIAT group\relax }}{3}}
\newlabel{table_riat_group}{{III}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {IV}{\ignorespaces Accuracy based on Packet Size group\relax }}{3}}
\newlabel{table_pkt_size_group}{{IV}{3}}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Attributes used in out studies\relax }}{4}}
\newlabel{table_attributes_description}{{I}{4}}
\@writefile{lot}{\contentsline {table}{\numberline {V}{\ignorespaces Accuracy based on Flow attribute group\relax }}{4}}
\newlabel{table_flow_group}{{V}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Percentage of Training data v/s Accuracy for Adaboost\relax }}{4}}
\newlabel{adaboost_selected_total}{{3}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Multiple Cluster Models}{4}}
\newlabel{sec:multi_cluster}{{IV}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-A}}Population Fraction}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {IV-B}}Description of the technique used for classification}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Evaluation}{5}}
\newlabel{sec:eval}{{V}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-A}}Datasets}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Percent of training data v/s Accuracy for Adaboost with Groups of Attributes.Plotting Adaboost with each group of attributes.\relax }}{5}}
\newlabel{fig:adaboost_attributes}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-B}}Cleaning}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-C}}Experimental Setup}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\unhbox \voidb@x \hbox {V-D}}Results}{5}}
\bibstyle{IEEEtranS}
\bibdata{IEEEabrv,references}
\bibcite{Bernaille:2006:EAI:1368436.1368445}{1}
\bibcite{Erman:2006:TCU:1162678.1162679}{2}
\bibcite{DBLP:conf/iwcmc/GrimaudoMB12}{3}
\bibcite{ACAS}{4}
\bibcite{DBLP:conf/noms/ParkWKH08}{5}
\bibcite{DBLP:conf/infocom/XieIKFN12}{6}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces \% of training data v/s Accuracy for Naive Bayes with Groups of Attributes. Plotting Naive Bayes with each group of attributes.\relax }}{6}}
\newlabel{fig:naive_attributes}{{5}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces \# Clusters v/s Accuracy of various strategies \relax }}{6}}
\newlabel{fig:hypo_updated}{{6}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{6}}
\newlabel{sec:conc}{{VI}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Percent of training data v/s Accuracy Comparing all the existing and proposed technique\relax }}{6}}
\newlabel{fig:super_hypo}{{7}{6}}
\@writefile{toc}{\contentsline {section}{References}{6}}
\bibcite{conf/IEEEcit/YeXWP09}{7}
